{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../input/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv(\"../input/cat_train_folds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'Circle', 'Polygon', 'Square', 'Star', 'Trapezoid', 'Triangle', nan}"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "set(list(df_k['nom_1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\"Freezing\" : 0,\n",
    "           \"Warm\" : 1,\n",
    "           \"Cold\" : 2,\n",
    "           \"Boiling Hot\": 3,\n",
    "           \"Hot\" : 4,\n",
    "           \"Lava Hot\" : 5 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,\"ord_2\"] = df.ord_2.map(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "Encoders require their input to be uniformly strings or numbers. Got ['float', 'str']",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/preprocessing/_label.py\u001b[0m in \u001b[0;36m_encode\u001b[0;34m(values, uniques, encode, check_unknown)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/preprocessing/_label.py\u001b[0m in \u001b[0;36m_encode_python\u001b[0;34m(values, uniques, encode)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muniques\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'str' and 'float'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-771fd2667475>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"ord_2\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mord_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"None\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlbl_enc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLabelEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"ord_2\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mlbl_enc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mord_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/preprocessing/_label.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \"\"\"\n\u001b[1;32m    255\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/preprocessing/_label.py\u001b[0m in \u001b[0;36m_encode\u001b[0;34m(values, uniques, encode, check_unknown)\u001b[0m\n\u001b[1;32m    115\u001b[0m             types = sorted(t.__qualname__\n\u001b[1;32m    116\u001b[0m                            for t in set(type(v) for v in values))\n\u001b[0;32m--> 117\u001b[0;31m             raise TypeError(\"Encoders require their input to be uniformly \"\n\u001b[0m\u001b[1;32m    118\u001b[0m                             f\"strings or numbers. Got {types}\")\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Encoders require their input to be uniformly strings or numbers. Got ['float', 'str']"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "df.loc[:,\"ord_2\"] = df.ord_2.fillna(\"None\")\n",
    "lbl_enc = preprocessing.LabelEncoder()\n",
    "df.loc[:,\"ord_2\"]= lbl_enc.fit_transform(df.ord_2.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "fold = 5\n",
    "df = pd.read_csv('../input/cat_train_folds.csv')\n",
    "features = [f for f in df.columns if f not in (\"id\", \"target\",\"kfold\")]\n",
    "for col in features:\n",
    "    df.loc[:,col] = df[col].astype(str).fillna(\"NONE\")\n",
    "\n",
    "df_train = df[df.kfold != fold].reset_index(drop = True)\n",
    "df_valid = df[df.kfold ==fold].reset_index(drop = True)\n",
    "X_train = df_train[features]\n",
    "\n",
    "X_valid= df_valid[features]\n",
    "\n",
    "categorical_features_indices = np.where(X_train.dtypes != np.float)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n       17, 18, 19, 20, 21, 22])"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "\n",
    "categorical_features_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "23"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "len(categorical_features_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'bin_3'"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "X_train.columns[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0         T\n1         T\n2         T\n3         T\n4         F\n         ..\n599995    F\n599996    T\n599997    T\n599998    F\n599999    F\nName: bin_3, Length: 600000, dtype: object"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "X_train.bin_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../input/adult_folds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "       age         workclass  fnlwgt     education  education.num  \\\n0       54           Private  213092       HS-grad              9   \n1       47           Private  142061  Some-college             10   \n2       20                 ?   40060  Some-college             10   \n3       38           Private  229236       HS-grad              9   \n4       49      Self-emp-inc   34998  Some-college             10   \n...    ...               ...     ...           ...            ...   \n32556   54  Self-emp-not-inc  226497  Some-college             10   \n32557   28           Private   59335     Bachelors             13   \n32558   39           Private  154641     Assoc-voc             11   \n32559   33           Private  268571  Some-college             10   \n32560   39           Private  179481       HS-grad              9   \n\n           marital.status        occupation    relationship   race     sex  \\\n0                Divorced     Other-service   Not-in-family  White  Female   \n1                Divorced   Exec-managerial       Unmarried  White  Female   \n2           Never-married                 ?       Own-child  White    Male   \n3      Married-civ-spouse  Transport-moving         Husband  Other    Male   \n4      Married-civ-spouse   Farming-fishing         Husband  White    Male   \n...                   ...               ...             ...    ...     ...   \n32556  Married-civ-spouse             Sales         Husband  White    Male   \n32557  Married-civ-spouse      Adm-clerical  Other-relative  White  Female   \n32558  Married-civ-spouse      Adm-clerical         Husband  White    Male   \n32559  Married-civ-spouse     Other-service         Husband  White    Male   \n32560       Never-married      Tech-support   Not-in-family  White    Male   \n\n       capital.gain  capital.loss  hours.per.week native.country income  kfold  \n0                 0             0              40  United-States  <=50K      0  \n1                 0             0              40  United-States  <=50K      0  \n2                 0             0              56  United-States  <=50K      0  \n3                 0             0              40    Puerto-Rico  <=50K      0  \n4                 0             0              60  United-States  <=50K      0  \n...             ...           ...             ...            ...    ...    ...  \n32556             0             0              50  United-States  <=50K      4  \n32557             0             0              15  United-States  <=50K      4  \n32558             0             0              40  United-States  <=50K      4  \n32559             0             0              40  United-States  <=50K      4  \n32560          4650             0              44  United-States  <=50K      4  \n\n[32561 rows x 16 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>workclass</th>\n      <th>fnlwgt</th>\n      <th>education</th>\n      <th>education.num</th>\n      <th>marital.status</th>\n      <th>occupation</th>\n      <th>relationship</th>\n      <th>race</th>\n      <th>sex</th>\n      <th>capital.gain</th>\n      <th>capital.loss</th>\n      <th>hours.per.week</th>\n      <th>native.country</th>\n      <th>income</th>\n      <th>kfold</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>54</td>\n      <td>Private</td>\n      <td>213092</td>\n      <td>HS-grad</td>\n      <td>9</td>\n      <td>Divorced</td>\n      <td>Other-service</td>\n      <td>Not-in-family</td>\n      <td>White</td>\n      <td>Female</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>47</td>\n      <td>Private</td>\n      <td>142061</td>\n      <td>Some-college</td>\n      <td>10</td>\n      <td>Divorced</td>\n      <td>Exec-managerial</td>\n      <td>Unmarried</td>\n      <td>White</td>\n      <td>Female</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>20</td>\n      <td>?</td>\n      <td>40060</td>\n      <td>Some-college</td>\n      <td>10</td>\n      <td>Never-married</td>\n      <td>?</td>\n      <td>Own-child</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>56</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>38</td>\n      <td>Private</td>\n      <td>229236</td>\n      <td>HS-grad</td>\n      <td>9</td>\n      <td>Married-civ-spouse</td>\n      <td>Transport-moving</td>\n      <td>Husband</td>\n      <td>Other</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>Puerto-Rico</td>\n      <td>&lt;=50K</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>49</td>\n      <td>Self-emp-inc</td>\n      <td>34998</td>\n      <td>Some-college</td>\n      <td>10</td>\n      <td>Married-civ-spouse</td>\n      <td>Farming-fishing</td>\n      <td>Husband</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>60</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>32556</th>\n      <td>54</td>\n      <td>Self-emp-not-inc</td>\n      <td>226497</td>\n      <td>Some-college</td>\n      <td>10</td>\n      <td>Married-civ-spouse</td>\n      <td>Sales</td>\n      <td>Husband</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>50</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>32557</th>\n      <td>28</td>\n      <td>Private</td>\n      <td>59335</td>\n      <td>Bachelors</td>\n      <td>13</td>\n      <td>Married-civ-spouse</td>\n      <td>Adm-clerical</td>\n      <td>Other-relative</td>\n      <td>White</td>\n      <td>Female</td>\n      <td>0</td>\n      <td>0</td>\n      <td>15</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>32558</th>\n      <td>39</td>\n      <td>Private</td>\n      <td>154641</td>\n      <td>Assoc-voc</td>\n      <td>11</td>\n      <td>Married-civ-spouse</td>\n      <td>Adm-clerical</td>\n      <td>Husband</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>32559</th>\n      <td>33</td>\n      <td>Private</td>\n      <td>268571</td>\n      <td>Some-college</td>\n      <td>10</td>\n      <td>Married-civ-spouse</td>\n      <td>Other-service</td>\n      <td>Husband</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>32560</th>\n      <td>39</td>\n      <td>Private</td>\n      <td>179481</td>\n      <td>HS-grad</td>\n      <td>9</td>\n      <td>Never-married</td>\n      <td>Tech-support</td>\n      <td>Not-in-family</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>4650</td>\n      <td>0</td>\n      <td>44</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n<p>32561 rows × 16 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "       id  bin_0  bin_1  bin_2 bin_3 bin_4 nom_0      nom_1    nom_2  \\\n0  209233    0.0    0.0    1.0     T     N  Blue  Trapezoid  Hamster   \n1  414905    0.0    0.0    0.0     F     N  Blue   Triangle      Dog   \n2   49751    0.0    0.0    0.0     F     N   Red   Triangle  Hamster   \n3  393397    0.0    0.0    0.0     F     Y  Blue     Circle      NaN   \n4  189244    0.0    0.0    0.0     F     N   Red   Triangle  Hamster   \n\n        nom_3  ... ord_0        ord_1     ord_2 ord_3 ord_4 ord_5  day month  \\\n0         NaN  ...   3.0       Expert      Warm     n     B    PS  4.0   1.0   \n1       China  ...   3.0  Grandmaster      Warm     d     F    Nh  4.0   8.0   \n2     Finland  ...   3.0       Novice  Freezing     c     Y    Nh  3.0   3.0   \n3       India  ...   3.0       Master  Freezing     a     M    ze  2.0  11.0   \n4  Costa Rica  ...   1.0       Expert       Hot     o     N    hG  6.0   5.0   \n\n  target kfold  \n0      1     0  \n1      0     0  \n2      0     0  \n3      0     0  \n4      0     0  \n\n[5 rows x 26 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>bin_0</th>\n      <th>bin_1</th>\n      <th>bin_2</th>\n      <th>bin_3</th>\n      <th>bin_4</th>\n      <th>nom_0</th>\n      <th>nom_1</th>\n      <th>nom_2</th>\n      <th>nom_3</th>\n      <th>...</th>\n      <th>ord_0</th>\n      <th>ord_1</th>\n      <th>ord_2</th>\n      <th>ord_3</th>\n      <th>ord_4</th>\n      <th>ord_5</th>\n      <th>day</th>\n      <th>month</th>\n      <th>target</th>\n      <th>kfold</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>209233</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>T</td>\n      <td>N</td>\n      <td>Blue</td>\n      <td>Trapezoid</td>\n      <td>Hamster</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>3.0</td>\n      <td>Expert</td>\n      <td>Warm</td>\n      <td>n</td>\n      <td>B</td>\n      <td>PS</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>414905</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>F</td>\n      <td>N</td>\n      <td>Blue</td>\n      <td>Triangle</td>\n      <td>Dog</td>\n      <td>China</td>\n      <td>...</td>\n      <td>3.0</td>\n      <td>Grandmaster</td>\n      <td>Warm</td>\n      <td>d</td>\n      <td>F</td>\n      <td>Nh</td>\n      <td>4.0</td>\n      <td>8.0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>49751</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>F</td>\n      <td>N</td>\n      <td>Red</td>\n      <td>Triangle</td>\n      <td>Hamster</td>\n      <td>Finland</td>\n      <td>...</td>\n      <td>3.0</td>\n      <td>Novice</td>\n      <td>Freezing</td>\n      <td>c</td>\n      <td>Y</td>\n      <td>Nh</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>393397</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>F</td>\n      <td>Y</td>\n      <td>Blue</td>\n      <td>Circle</td>\n      <td>NaN</td>\n      <td>India</td>\n      <td>...</td>\n      <td>3.0</td>\n      <td>Master</td>\n      <td>Freezing</td>\n      <td>a</td>\n      <td>M</td>\n      <td>ze</td>\n      <td>2.0</td>\n      <td>11.0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>189244</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>F</td>\n      <td>N</td>\n      <td>Red</td>\n      <td>Triangle</td>\n      <td>Hamster</td>\n      <td>Costa Rica</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>Expert</td>\n      <td>Hot</td>\n      <td>o</td>\n      <td>N</td>\n      <td>hG</td>\n      <td>6.0</td>\n      <td>5.0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 26 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "f for f in df.columns if f not in (\"id\",\"target\",\"kfold\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0         N\n1         N\n2         N\n3         Y\n4         N\n         ..\n599995    Y\n599996    Y\n599997    Y\n599998    N\n599999    Y\nName: bin_4, Length: 600000, dtype: object"
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "df['bin_4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['bin_0',\n 'bin_1',\n 'bin_2',\n 'bin_3',\n 'bin_4',\n 'nom_0',\n 'nom_1',\n 'nom_2',\n 'nom_3',\n 'nom_4',\n 'nom_5',\n 'nom_6',\n 'nom_7',\n 'nom_8',\n 'nom_9',\n 'ord_0',\n 'ord_1',\n 'ord_2',\n 'ord_3',\n 'ord_4',\n 'ord_5',\n 'day',\n 'month']"
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "bin_0\nbin_1\nbin_2\nbin_3\nbin_4\nnom_0\nnom_1\nnom_2\nnom_3\nnom_4\nnom_5\nnom_6\nnom_7\nnom_8\nnom_9\nord_0\nord_1\nord_2\nord_3\nord_4\nord_5\nday\nmonth\nbin_0\nbin_1\nbin_2\nbin_3\nbin_4\nnom_0\nnom_1\nnom_2\nnom_3\nnom_4\nnom_5\nnom_6\nnom_7\nnom_8\nnom_9\nord_0\nord_1\nord_2\nord_3\nord_4\nord_5\nday\nmonth\nbin_0\nbin_1\nbin_2\nbin_3\nbin_4\nnom_0\nnom_1\nnom_2\nnom_3\nnom_4\nnom_5\nnom_6\nnom_7\nnom_8\nnom_9\nord_0\nord_1\nord_2\nord_3\nord_4\nord_5\nday\nmonth\nbin_0\nbin_1\nbin_2\nbin_3\nbin_4\nnom_0\nnom_1\nnom_2\nnom_3\nnom_4\nnom_5\nnom_6\nnom_7\nnom_8\nnom_9\nord_0\nord_1\nord_2\nord_3\nord_4\nord_5\nday\nmonth\nbin_0\nbin_1\nbin_2\nbin_3\nbin_4\nnom_0\nnom_1\nnom_2\nnom_3\nnom_4\nnom_5\nnom_6\nnom_7\nnom_8\nnom_9\n"
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import joblib\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn import metrics, preprocessing\n",
    "\n",
    "for col in features:\n",
    "        df.loc[:,col] = df[col].astype(str).fillna(\"NONE\")\n",
    "        #encode all features with label encoder individually\n",
    "        #in a live setting all label encoders need to be saved\n",
    "        \n",
    "        for feat in features:\n",
    "            print(feat)\n",
    "            lbl_enc = preprocessing.LabelEncoder()\n",
    "            df.loc[:,feat] = df[feat].astype(str)\n",
    "            lbl_enc = lbl_enc.fit(df[feat].values)\n",
    "            df.loc[:, feat] = lbl_enc.fit_transform(df[feat].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import joblib\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn import metrics, preprocessing\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras import backend as k\n",
    "from tensorflow.keras import utils\n",
    "\n",
    "def create_model(data, catcols):\n",
    "\n",
    "    '''\n",
    "    this funciton returns a compiled tf.keras model for entitiy embeddings\n",
    "    :param data: this is a pandas dataframe\n",
    "    :param catcols: list of categorical column names\n",
    "    :return: complied tf.keras model\n",
    "    '''\n",
    "    #init the list of inputs for embedding\n",
    "    inputs =[]\n",
    "    #init the list of outputs for embedding\n",
    "    outputs= []\n",
    "    #loop over all categorical columns\n",
    "    for c in catcols:\n",
    "\n",
    "        #find the number of unique values in the column\n",
    "        num_unique_values= int(data[c].nunique())\n",
    "        #simple dimension of embedding calculator\n",
    "        #min size is half the number of unbique values\n",
    "        #max size is 50. max size depends on the number of values\n",
    "        #categories too. 50 is quite sufficient most of the times\n",
    "        #but if you have millions of unique values, you might need a larger dimenion\n",
    "\n",
    "        embed_dim = int(min(np.ceil((num_unique_values)/2), 50))\n",
    "        #simple keras input layer with size 1\n",
    "\n",
    "        inp = layers.Input(shape = (1,))\n",
    "        #add embedding layer to raw input\n",
    "        #embedding size is alwasy 1 more than unique values in input\n",
    "\n",
    "        out = layers.Embedding(num_unique_values + 1, embed_dim, name = c)(inp)\n",
    "\n",
    "        #1-d spatial dropout is the standard for embedding layers\n",
    "        #it can be used in nlp tasks as well\n",
    "\n",
    "        out = layers.SpatialDropout1D(0.3)(out)\n",
    "\n",
    "        #reshape the input to the dimensions of embedding\n",
    "        #this becomes our output layer for current feature\n",
    "\n",
    "        out = layers.Reshape(target_shape = (embed_dim,))(out)\n",
    "\n",
    "        #add input to input list\n",
    "        inputs.append(inp)\n",
    "        #add output to output list\n",
    "        outputs.append(out)\n",
    "\n",
    "\n",
    "    #concatenate all output layers\n",
    "    X = layers.Concatenate()(outputs)\n",
    "    # add a batchnorm layer\n",
    "    # from here, everything is up to you\n",
    "    # you can try different architecture\n",
    "    # add numerical features here or in concatonate layer\n",
    "    X = layers.BatchNormalization()(X)\n",
    "\n",
    "    # a bunch of dense layers with dropout\n",
    "    # start with 1 or two layers only\n",
    "    X = layers.Dense(300,activation = 'relu')(X)\n",
    "    X = layers.Dropout(0.3)(X)\n",
    "    X = layers.BatchNormalization()(X)\n",
    "\n",
    "    #using softmax and treating it as a two class problem\n",
    "    # sigmoid can also be used but then we need only 1 output class\n",
    "    y = layers.Dense(2, activation = 'softmax')(X)\n",
    "\n",
    "    model = Model(inputs = inputs ,outputs = y)\n",
    "    #compile the model\n",
    "    # we use adam and binary cross entropy\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = 'adam')\n",
    "\n",
    "    return model \n",
    "def run(fold):\n",
    "    df = pd.read_csv('../input/cat_train_folds.csv')\n",
    "    features = [\n",
    "        f for f in df.columns if f not in (\"id\",\"target\",\"kfold\")\n",
    "    ]\n",
    "    #fill all Na with NONE\n",
    "    for col in features:\n",
    "        df.loc[:,col] = df[col].astype(str).fillna(\"NONE\")\n",
    "        #encode all features with label encoder individually\n",
    "        #in a live setting all label encoders need to be saved\n",
    "        \n",
    "        for feat in features:\n",
    "            df.loc[:,feat] = df[feat].astype(str)\n",
    "            lbl_enc = preprocessing.LabelEncoder()\n",
    "            lbl_enc = lbl_enc.fit(df[feat].values)\n",
    "            df.loc[:, feat] = lbl_enc.fit_transform(df[feat].astype(str).values)\n",
    "\n",
    "        #get trainign data using folds\n",
    "\n",
    "        df_train= df[df.kfold != fold].reset_index(drop = True)\n",
    "        df_valid = df[df.kfold ==fold].reset_index(drop = True)\n",
    "\n",
    "        model = create_model(df, features)\n",
    "        #our features are a list of list\n",
    "        Xtrain = []\n",
    "        for k in range(len(features)):\n",
    "            Xtrain.append([])\n",
    "        Xvalid = []\n",
    "        for k in range(len(features)):\n",
    "            Xvalid.append([])\n",
    "\n",
    "\n",
    "        for k in range(len(features)):\n",
    "            Xtrain[k].append(np.asarray(df_train[features].values[:,k]))\n",
    "\n",
    "        # print(Xtrain) \n",
    "        # for k in range(len(features)):\n",
    "        #     Xvalid[k].append(np.asarray(df_valid[features].values[:,k]))\n",
    "    \n",
    "\n",
    "        # Xtrain =[np.asarray(df_train[features].values[:,k])  for k in range(len(features))]\n",
    "        # Xvalid = [np.asarray(df_valid[features].values[:,k])  for k in range(len(features))]     \n",
    "        # for i in range(len(Xtrain)):\n",
    "        #     Xtrain = np.asarray(Xtrain[i]) \n",
    "        # for i in range(len(Xvalid)):\n",
    "\n",
    "        #     Xvalid = np.asarray(Xvalid[i])\n",
    "\n",
    "\n",
    "        print(Xtrain[0].shape)\n",
    "        #Xtrain = df_train[features].values\n",
    "        #Xvalid = df_valid[features].values\n",
    "        print(f'xtrain shape: {len(Xtrain)}')\n",
    "        ytrain = df_train.target.values\n",
    "        yvalid = df_train.target.values\n",
    "        \n",
    "        #concert target columns to categories\n",
    "        #this is just binarization\n",
    "\n",
    "        ytrain_cat = utils.to_categorical(ytrain)\n",
    "        print(f'y_traincat shape {len(ytrain_cat)}')\n",
    "        yvalid_cat = utils.to_categorical(yvalid)\n",
    "\n",
    "   \n",
    "        #fit the model\n",
    "        print(f'y_traincat shape {ytrain_cat.shape}')\n",
    "\n",
    "        model.fit(Xtrain,ytrain_cat, validation_data = (Xvalid, yvalid_cat), verbose = 1, batch_size =1024, epochs = 3)\n",
    "\n",
    "\n",
    "        valid_preds = model.predict(Xvalid)[:,1]\n",
    "        print(metrics.roc_auc_score(yvalid, valid_preds))\n",
    "\n",
    "        #clear session to free gpu memory\n",
    "\n",
    "        k.clear_session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(480000,)\nxtrain shape: 23\ny_traincat shape 480000\ny_traincat shape (480000, 2)\n"
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous:\n  x sizes: 23\n  y sizes: 480000\nPlease provide data which shares the same first dimension.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-758486053e99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-34-5b4aacf49be5>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(fold)\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'y_traincat shape {ytrain_cat.shape}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mytrain_cat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mXvalid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myvalid_cat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    800\u001b[0m          \u001b[0mtraining_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRespectCompiledTrainableState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m       \u001b[0;31m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 802\u001b[0;31m       data_handler = data_adapter.DataHandler(\n\u001b[0m\u001b[1;32m    803\u001b[0m           \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m           \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m     \u001b[0madapter_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m     self._adapter = adapter_cls(\n\u001b[0m\u001b[1;32m   1101\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    280\u001b[0m             label, \", \".join(str(i.shape[0]) for i in nest.flatten(data)))\n\u001b[1;32m    281\u001b[0m       \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"Please provide data which shares the same first dimension.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m     \u001b[0mnum_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 23\n  y sizes: 480000\nPlease provide data which shares the same first dimension."
     ]
    }
   ],
   "source": [
    "run(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "x (10, 2, 224, 224, 20)\ny (2, 3)\n"
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-859669ab9bc3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "x = []\n",
    "for i in range(10):\n",
    "  x.append([])\n",
    "data = np.random.rand(2,10,224, 224, 20)\n",
    "for data_vector in data:\n",
    "  for index in range(10):\n",
    "    x[index].append(data_vector[index]) \n",
    "\n",
    "for i in range(10):\n",
    "  x[i] = np.asarray(x[i]) \n",
    "   \n",
    "y = np.random.rand(2,3)\n",
    "print('x',np.asarray(x).shape)\n",
    "print('y',y.shape)\n",
    "model.fit(x,y,epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}